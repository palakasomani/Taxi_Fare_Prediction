{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data (2000000, 8)\n",
      "Shape of Testing Data (9914, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(77, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(\"train.csv\",nrows=2000000)\n",
    "print(\"Shape of Training Data\",train.shape)\n",
    "test=pd.read_csv(\"test.csv\")\n",
    "print(\"Shape of Testing Data\", test.shape)\n",
    "train.loc[train['fare_amount']<0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeDays(day_of_week):\n",
    "    day_dict={'Sunday':0,'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6}\n",
    "    return day_dict[day_of_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    boundary={'min_lng':-74.263242,\n",
    "              'min_lat':40.573143,\n",
    "              'max_lng':-72.986532, \n",
    "              'max_lat':41.709555}\n",
    "    \n",
    "    data['pickup_datetime']=pd.to_datetime(data['pickup_datetime'],format='%Y-%m-%d %H:%M:%S UTC')\n",
    "    data['pickup_day']=data['pickup_datetime'].apply(lambda x:x.day)\n",
    "    data['pickup_hour']=data['pickup_datetime'].apply(lambda x:x.hour)\n",
    "    data['pickup_day_of_week']=data['pickup_datetime'].apply(lambda x:calendar.day_name[x.weekday()])\n",
    "    data['pickup_month']=data['pickup_datetime'].apply(lambda x:x.month)\n",
    "    data['pickup_year']=data['pickup_datetime'].apply(lambda x:x.year)\n",
    "    if 'fare_amount' in data.columns:\n",
    "        data=data[data['fare_amount']>=0]\n",
    "        data.loc[~((data.pickup_longitude >= boundary['min_lng'] ) & (data.pickup_longitude <= boundary['max_lng']) &\n",
    "            (data.pickup_latitude >= boundary['min_lat']) & (data.pickup_latitude <= boundary['max_lat']) &\n",
    "            (data.dropoff_longitude >= boundary['min_lng']) & (data.dropoff_longitude <= boundary['max_lng']) &\n",
    "            (data.dropoff_latitude >=boundary['min_lat']) & (data.dropoff_latitude <= boundary['max_lat'])),'is_outlier_loc']=1\n",
    "        data.loc[((data.pickup_longitude >= boundary['min_lng'] ) & (data.pickup_longitude <= boundary['max_lng']) &\n",
    "            (data.pickup_latitude >= boundary['min_lat']) & (data.pickup_latitude <= boundary['max_lat']) &\n",
    "            (data.dropoff_longitude >= boundary['min_lng']) & (data.dropoff_longitude <= boundary['max_lng']) &\n",
    "            (data.dropoff_latitude >=boundary['min_lat']) & (data.dropoff_latitude <= boundary['max_lat'])),'is_outlier_loc']=0\n",
    "\n",
    "    #print(\"Outlier vs Non Outlier Counts\")\n",
    "    #print(data['is_outlier_loc'].value_counts())\n",
    "\n",
    "    # Let us drop rows, where location is outlier\n",
    "        data=data.loc[data['is_outlier_loc']==0]\n",
    "        data.drop(['is_outlier_loc'],axis=1,inplace=True)\n",
    "    \n",
    "    data=data[data['passenger_count']<=8]\n",
    "    data['pickup_day_of_week']=data['pickup_day_of_week'].apply(lambda x:encodeDays(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1957458, 13)\n",
      "(9914, 12)\n"
     ]
    }
   ],
   "source": [
    "train=clean_data(train)\n",
    "test=clean_data(test)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDataForModelling(data,target,drop_cols,is_train=True,split=0.25):\n",
    "    data_1=data.drop(drop_cols,axis=1)\n",
    "    # One hot Encoding\n",
    "    data_1=pd.get_dummies(data_1)\n",
    "    if is_train==True:\n",
    "        X=data_1.drop([target],axis=1)\n",
    "        y=data_1[target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=split,random_state=123)\n",
    "        \n",
    "        print(\"Shape of Training Features\",X_train.shape)\n",
    "        print(\"Shape of Validation Features \",X_test.shape)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        print (\"Shape of Test Data\",data_1.shape)\n",
    "        return data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Features (1761712, 10)\n",
      "Shape of Validation Features  (195746, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=processDataForModelling(train,'fare_amount',drop_cols=['key','pickup_datetime'],is_train=True,split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Test Data (9914, 10)\n"
     ]
    }
   ],
   "source": [
    "test_data=processDataForModelling(test,'fare_amount',drop_cols=['key','pickup_datetime'],is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_fare=round(np.mean(y_train),2)\n",
    "avg_fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basline RMSE of Validation data : 9.642490185825663\n"
     ]
    }
   ],
   "source": [
    "baseline_pred=np.repeat(avg_fare,y_test.shape[0])\n",
    "baseline_rmse=np.sqrt(mean_squared_error(baseline_pred, y_test))\n",
    "print(\"Basline RMSE of Validation data :\",baseline_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Linear Regression is  8.191149460055973\n"
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "y_pred=np.round(lm.predict(X_test),2)\n",
    "lm_rmse=np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "print(\"RMSE for Linear Regression is \",lm_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=883, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 883,n_jobs=-1)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Random Forest is  3.991460608341765\n"
     ]
    }
   ],
   "source": [
    "rf_pred= rf.predict(X_test)\n",
    "rf_rmse=np.sqrt(mean_squared_error(rf_pred, y_test))\n",
    "print(\"RMSE for Random Forest is \",rf_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LightGBM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=lgb.Dataset(X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves':31, 'num_trees':5000, 'objective':'regression'}\n",
    "param['metric'] = 'l2_root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's rmse: 5.08278 + 0.0934834\n",
      "[40]\tcv_agg's rmse: 4.54805 + 0.105815\n",
      "[60]\tcv_agg's rmse: 4.34493 + 0.114242\n",
      "[80]\tcv_agg's rmse: 4.25264 + 0.115786\n",
      "[100]\tcv_agg's rmse: 4.19623 + 0.117897\n",
      "[120]\tcv_agg's rmse: 4.15468 + 0.118655\n",
      "[140]\tcv_agg's rmse: 4.1218 + 0.120755\n",
      "[160]\tcv_agg's rmse: 4.09327 + 0.119202\n",
      "[180]\tcv_agg's rmse: 4.07281 + 0.12147\n",
      "[200]\tcv_agg's rmse: 4.05325 + 0.121248\n",
      "[220]\tcv_agg's rmse: 4.03676 + 0.122824\n",
      "[240]\tcv_agg's rmse: 4.02188 + 0.122723\n",
      "[260]\tcv_agg's rmse: 4.0102 + 0.122141\n",
      "[280]\tcv_agg's rmse: 4.0009 + 0.122785\n",
      "[300]\tcv_agg's rmse: 3.99187 + 0.122125\n",
      "[320]\tcv_agg's rmse: 3.98446 + 0.121258\n",
      "[340]\tcv_agg's rmse: 3.9759 + 0.121333\n",
      "[360]\tcv_agg's rmse: 3.96868 + 0.121491\n",
      "[380]\tcv_agg's rmse: 3.96195 + 0.12139\n",
      "[400]\tcv_agg's rmse: 3.9576 + 0.122478\n",
      "[420]\tcv_agg's rmse: 3.95238 + 0.122116\n",
      "[440]\tcv_agg's rmse: 3.94763 + 0.122401\n",
      "[460]\tcv_agg's rmse: 3.94354 + 0.122092\n",
      "[480]\tcv_agg's rmse: 3.93956 + 0.122357\n",
      "[500]\tcv_agg's rmse: 3.93707 + 0.122438\n",
      "[520]\tcv_agg's rmse: 3.93397 + 0.1225\n",
      "[540]\tcv_agg's rmse: 3.93017 + 0.122392\n",
      "[560]\tcv_agg's rmse: 3.92687 + 0.121936\n",
      "[580]\tcv_agg's rmse: 3.9244 + 0.122029\n",
      "[600]\tcv_agg's rmse: 3.92172 + 0.122481\n",
      "[620]\tcv_agg's rmse: 3.9195 + 0.12179\n",
      "[640]\tcv_agg's rmse: 3.91725 + 0.121286\n",
      "[660]\tcv_agg's rmse: 3.91486 + 0.120902\n",
      "[680]\tcv_agg's rmse: 3.91282 + 0.121075\n",
      "[700]\tcv_agg's rmse: 3.91111 + 0.120278\n",
      "[720]\tcv_agg's rmse: 3.90883 + 0.120196\n",
      "[740]\tcv_agg's rmse: 3.90783 + 0.119667\n",
      "[760]\tcv_agg's rmse: 3.9062 + 0.119686\n",
      "[780]\tcv_agg's rmse: 3.90473 + 0.119942\n",
      "[800]\tcv_agg's rmse: 3.90362 + 0.120114\n",
      "[820]\tcv_agg's rmse: 3.90176 + 0.119785\n",
      "[840]\tcv_agg's rmse: 3.90037 + 0.119812\n",
      "[860]\tcv_agg's rmse: 3.89989 + 0.120192\n",
      "[880]\tcv_agg's rmse: 3.89883 + 0.120199\n",
      "[900]\tcv_agg's rmse: 3.89774 + 0.120137\n",
      "[920]\tcv_agg's rmse: 3.89657 + 0.120245\n",
      "[940]\tcv_agg's rmse: 3.89526 + 0.120029\n",
      "[960]\tcv_agg's rmse: 3.89441 + 0.12045\n",
      "[980]\tcv_agg's rmse: 3.89359 + 0.120304\n",
      "[1000]\tcv_agg's rmse: 3.89241 + 0.120397\n",
      "[1020]\tcv_agg's rmse: 3.89182 + 0.120395\n",
      "[1040]\tcv_agg's rmse: 3.89114 + 0.120853\n",
      "[1060]\tcv_agg's rmse: 3.89027 + 0.121034\n",
      "[1080]\tcv_agg's rmse: 3.88958 + 0.12103\n",
      "[1100]\tcv_agg's rmse: 3.88908 + 0.121144\n",
      "[1120]\tcv_agg's rmse: 3.88851 + 0.121096\n",
      "[1140]\tcv_agg's rmse: 3.88806 + 0.121345\n",
      "[1160]\tcv_agg's rmse: 3.88751 + 0.12174\n",
      "[1180]\tcv_agg's rmse: 3.88663 + 0.122211\n",
      "[1200]\tcv_agg's rmse: 3.88609 + 0.121933\n",
      "[1220]\tcv_agg's rmse: 3.88545 + 0.121847\n",
      "[1240]\tcv_agg's rmse: 3.88514 + 0.121463\n",
      "[1260]\tcv_agg's rmse: 3.88455 + 0.12128\n",
      "[1280]\tcv_agg's rmse: 3.88403 + 0.121054\n",
      "[1300]\tcv_agg's rmse: 3.88334 + 0.121065\n",
      "[1320]\tcv_agg's rmse: 3.88324 + 0.121393\n",
      "[1340]\tcv_agg's rmse: 3.88254 + 0.121268\n",
      "[1360]\tcv_agg's rmse: 3.88205 + 0.121112\n",
      "[1380]\tcv_agg's rmse: 3.88183 + 0.121347\n",
      "[1400]\tcv_agg's rmse: 3.88139 + 0.121421\n",
      "[1420]\tcv_agg's rmse: 3.88124 + 0.121518\n",
      "[1440]\tcv_agg's rmse: 3.88098 + 0.121175\n",
      "[1460]\tcv_agg's rmse: 3.88022 + 0.121104\n",
      "[1480]\tcv_agg's rmse: 3.87999 + 0.12119\n",
      "[1500]\tcv_agg's rmse: 3.8797 + 0.121053\n",
      "[1520]\tcv_agg's rmse: 3.87929 + 0.120884\n"
     ]
    }
   ],
   "source": [
    "num_round=5000\n",
    "cv_results = lgb.cv(param, train_data, num_boost_round=num_round, nfold=10,verbose_eval=20, early_stopping_rounds=20,stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "lgb_bst=lgb.train(param,train_data,len(cv_results['rmse-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Light GBM is  3.887381180779112\n"
     ]
    }
   ],
   "source": [
    "lgb_pred = lgb_bst.predict(X_test)\n",
    "lgb_rmse=np.sqrt(mean_squared_error(lgb_pred, y_test))\n",
    "print(\"RMSE for Light GBM is \",lgb_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "dtest = xgb.DMatrix(X_test,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = {'objective':'reg:linear','eval_metric':'rmse'}\n",
    "xgb_cv=xgb.cv(xgb_param, dtrain, num_boost_round=200, nfold=5,early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrounds=xgb_cv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbg_model=xgb.train(params={'objective':'reg:linear','eval_metric':'rmse'}\n",
    "                    ,dtrain=dtrain,num_boost_round=nrounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for XGBOOST is  3.8479755782680103\n"
     ]
    }
   ],
   "source": [
    "xgb_pred=xbg_model.predict(dtest)\n",
    "xgb_rmse=np.sqrt(mean_squared_error(xgb_pred, y_test))\n",
    "print(\"RMSE for XGBOOST is \",xgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred=pd.DataFrame()\n",
    "model_pred['model_name']=['Linear Regression','Random Forest','Light GBM','XGBOOST']\n",
    "model_pred['test_rmse']=[lm_rmse,rf_rmse,lgb_rmse,xgb_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_train_rmse=np.sqrt(mean_squared_error(lm.predict(X_train), y_train))\n",
    "rf_train_rmse=np.sqrt(mean_squared_error(rf.predict(X_train),y_train))\n",
    "lgb_train_rmse=np.sqrt(mean_squared_error(lgb_bst.predict(X_train),y_train))\n",
    "xgb_train_rmse=np.sqrt(mean_squared_error(xbg_model.predict(dtrain),y_train))\n",
    "\n",
    "model_pred['train_rmse']=[lm_train_rmse,rf_train_rmse,lgb_train_rmse,xgb_train_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>8.191149</td>\n",
       "      <td>8.218900</td>\n",
       "      <td>0.027750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.991461</td>\n",
       "      <td>1.718659</td>\n",
       "      <td>-2.272802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Light GBM</td>\n",
       "      <td>3.887381</td>\n",
       "      <td>3.008072</td>\n",
       "      <td>-0.879309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>3.847976</td>\n",
       "      <td>3.386853</td>\n",
       "      <td>-0.461123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  test_rmse  train_rmse  variance\n",
       "0  Linear Regression   8.191149    8.218900  0.027750\n",
       "1      Random Forest   3.991461    1.718659 -2.272802\n",
       "2          Light GBM   3.887381    3.008072 -0.879309\n",
       "3            XGBOOST   3.847976    3.386853 -0.461123"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred['variance']=model_pred['train_rmse'] - model_pred['test_rmse']\n",
    "model_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest has very high difference in the train and test RMSE(though train rmse is the minimum).we will thus consider LightGBM as the model and add features and tune this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_airports={'JFK':{'min_lng':-73.8352,\n",
    "     'min_lat':40.6195,\n",
    "     'max_lng':-73.7401, \n",
    "     'max_lat':40.6659},\n",
    "              \n",
    "    'EWR':{'min_lng':-74.1925,\n",
    "            'min_lat':40.6700, \n",
    "            'max_lng':-74.1531, \n",
    "            'max_lat':40.7081\n",
    "\n",
    "        },\n",
    "    'LaGuardia':{'min_lng':-73.8895, \n",
    "                  'min_lat':40.7664, \n",
    "                  'max_lng':-73.8550, \n",
    "                  'max_lat':40.7931\n",
    "        \n",
    "    }\n",
    "    \n",
    "}\n",
    "def isAirport(latitude,longitude,airport_name='JFK'):\n",
    "    \n",
    "    if latitude>=nyc_airports[airport_name]['min_lat'] and latitude<=nyc_airports[airport_name]['max_lat'] and longitude>=nyc_airports[airport_name]['min_lng'] and longitude<=nyc_airports[airport_name]['max_lng']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['is_pickup_la_guardia']=X_train.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'LaGuardia'),axis=1)\n",
    "X_train['is_dropoff_la_guardia']=X_train.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'LaGuardia'),axis=1)\n",
    "X_train['is_pickup_EWR']=X_train.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'EWR'),axis=1)\n",
    "X_train['is_dropoff_EWR']=X_train.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'EWR'),axis=1)\n",
    "X_train['is_pickup_JFK']=X_train.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'JFK'),axis=1)\n",
    "X_train['is_dropoff_JFK']=X_train.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'JFK'),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test['is_pickup_la_guardia']=X_test.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'LaGuardia'),axis=1)\n",
    "X_test['is_dropoff_la_guardia']=X_test.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'LaGuardia'),axis=1)\n",
    "X_test['is_pickup_EWR']=X_test.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'EWR'),axis=1)\n",
    "X_test['is_dropoff_EWR']=X_test.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'EWR'),axis=1)\n",
    "X_test['is_pickup_JFK']=X_test.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'JFK'),axis=1)\n",
    "X_test['is_dropoff_JFK']=X_test.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'JFK'),axis=1)\n",
    "\n",
    "\n",
    "test['is_pickup_la_guardia']=test.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'LaGuardia'),axis=1)\n",
    "test['is_dropoff_la_guardia']=test.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'LaGuardia'),axis=1)\n",
    "test['is_pickup_EWR']=test.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'EWR'),axis=1)\n",
    "test['is_dropoff_EWR']=test.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'EWR'),axis=1)\n",
    "test['is_pickup_JFK']=test.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'JFK'),axis=1)\n",
    "test['is_dropoff_JFK']=test.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'JFK'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_boroughs={\n",
    "    'manhattan':{\n",
    "        'min_lng':-74.0479,\n",
    "        'min_lat':40.6829,\n",
    "        'max_lng':-73.9067,\n",
    "        'max_lat':40.8820\n",
    "    },\n",
    "    \n",
    "    'queens':{\n",
    "        'min_lng':-73.9630,\n",
    "        'min_lat':40.5431,\n",
    "        'max_lng':-73.7004,\n",
    "        'max_lat':40.8007\n",
    "\n",
    "    },\n",
    "\n",
    "    'brooklyn':{\n",
    "        'min_lng':-74.0421,\n",
    "        'min_lat':40.5707,\n",
    "        'max_lng':-73.8334,\n",
    "        'max_lat':40.7395\n",
    "\n",
    "    },\n",
    "\n",
    "    'bronx':{\n",
    "        'min_lng':-73.9339,\n",
    "        'min_lat':40.7855,\n",
    "        'max_lng':-73.7654,\n",
    "        'max_lat':40.9176\n",
    "\n",
    "    },\n",
    "\n",
    "    'staten_island':{\n",
    "        'min_lng':-74.2558,\n",
    "        'min_lat':40.4960,\n",
    "        'max_lng':-74.0522,\n",
    "        'max_lat':40.6490\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBorough(lat,lng):\n",
    "    \n",
    "    locs=nyc_boroughs.keys()\n",
    "    for loc in locs:\n",
    "        if lat>=nyc_boroughs[loc]['min_lat'] and lat<=nyc_boroughs[loc]['max_lat'] and lng>=nyc_boroughs[loc]['min_lng'] and lng<=nyc_boroughs[loc]['max_lng']:\n",
    "            return loc\n",
    "    return 'others'\n",
    "X_train['pickup_borough']=X_train.apply(lambda row:getBorough(row['pickup_latitude'],row['pickup_longitude']),axis=1)\n",
    "X_train['dropoff_borough']=X_train.apply(lambda row:getBorough(row['dropoff_latitude'],row['dropoff_longitude']),axis=1)\n",
    "X_test['pickup_borough']=X_test.apply(lambda row:getBorough(row['pickup_latitude'],row['pickup_longitude']),axis=1)\n",
    "X_test['dropoff_borough']=X_test.apply(lambda row:getBorough(row['dropoff_latitude'],row['dropoff_longitude']),axis=1)\n",
    "\n",
    "test['pickup_borough']=test.apply(lambda row:getBorough(row['pickup_latitude'],row['pickup_longitude']),axis=1)\n",
    "test['dropoff_borough']=test.apply(lambda row:getBorough(row['dropoff_latitude'],row['dropoff_longitude']),axis=1)\n",
    "\n",
    "X_train=pd.get_dummies(X_train)\n",
    "X_test=pd.get_dummies(X_test)\n",
    "test=pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_manhattan_boundary={'min_lng': -74.0194,\n",
    "                          'min_lat':40.6997,\n",
    "                          'max_lng':-73.9716,\n",
    "                          'max_lat':40.7427}\n",
    "\n",
    "def isLowerManhattan(lat,lng):\n",
    "    if lat>=lower_manhattan_boundary['min_lat'] and lat<=lower_manhattan_boundary['max_lat'] and lng>=lower_manhattan_boundary['min_lng'] and lng<=lower_manhattan_boundary['max_lng']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['is_pickup_lower_manhattan']=X_train.apply(lambda row:isLowerManhattan(row['pickup_latitude'],row['pickup_longitude']),axis=1)\n",
    "X_train['is_dropoff_lower_manhattan']=X_train.apply(lambda row:isLowerManhattan(row['dropoff_latitude'],row['dropoff_longitude']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['is_pickup_lower_manhattan']=X_test.apply(lambda row:isLowerManhattan(row['pickup_latitude'],row['pickup_longitude']),axis=1)\n",
    "X_test['is_dropoff_lower_manhattan']=X_test.apply(lambda row:isLowerManhattan(row['dropoff_latitude'],row['dropoff_longitude']),axis=1)\n",
    "\n",
    "test['is_pickup_lower_manhattan']=test.apply(lambda row:isLowerManhattan(row['pickup_latitude'],row['pickup_longitude']),axis=1)\n",
    "test['is_dropoff_lower_manhattan']=test.apply(lambda row:isLowerManhattan(row['dropoff_latitude'],row['dropoff_longitude']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(lat1,lon1,lat2,lon2):\n",
    "    p = 0.017453292519943295 \n",
    "    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n",
    "    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr=(-73.8733, 40.7746)\n",
    "jfk=(-73.7900, 40.6437)\n",
    "ewr=(-74.1843, 40.6924)\n",
    "\n",
    "test['pickup_distance_jfk']=test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],jfk[1],jfk[0]),axis=1)\n",
    "test['dropoff_distance_jfk']=test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],jfk[1],jfk[0]),axis=1)\n",
    "test['pickup_distance_ewr']=test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],ewr[1],ewr[0]),axis=1)\n",
    "test['dropoff_distance_ewr']=test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],ewr[1],ewr[0]),axis=1)\n",
    "test['pickup_distance_laguardia']=test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],lgr[1],lgr[0]),axis=1)\n",
    "test['dropoff_distance_laguardia']=test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],lgr[1],lgr[0]),axis=1)\n",
    "\n",
    "X_train['pickup_distance_jfk']=X_train.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],jfk[1],jfk[0]),axis=1)\n",
    "X_train['dropoff_distance_jfk']=X_train.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],jfk[1],jfk[0]),axis=1)\n",
    "X_train['pickup_distance_ewr']=X_train.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],ewr[1],ewr[0]),axis=1)\n",
    "X_train['dropoff_distance_ewr']=X_train.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],ewr[1],ewr[0]),axis=1)\n",
    "X_train['pickup_distance_laguardia']=X_train.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],lgr[1],lgr[0]),axis=1)\n",
    "X_train['dropoff_distance_laguardia']=X_train.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],lgr[1],lgr[0]),axis=1)\n",
    "\n",
    "X_test['pickup_distance_jfk']=X_test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],jfk[1],jfk[0]),axis=1)\n",
    "X_test['dropoff_distance_jfk']=X_test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],jfk[1],jfk[0]),axis=1)\n",
    "X_test['pickup_distance_ewr']=X_test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],ewr[1],ewr[0]),axis=1)\n",
    "X_test['dropoff_distance_ewr']=X_test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],ewr[1],ewr[0]),axis=1)\n",
    "X_test['pickup_distance_laguardia']=X_test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],lgr[1],lgr[0]),axis=1)\n",
    "X_test['dropoff_distance_laguardia']=X_test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],lgr[1],lgr[0]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan=(-73.9664, 40.7909)\n",
    "queens=(-73.8317, 40.7038)\n",
    "brooklyn=(-73.9489, 40.6551)\n",
    "bronx=(-73.8568, 40.8572)\n",
    "staten_island=(-74.1540, 40.5725)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test['pickup_distance_manhattan']=test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],manhattan[1],manhattan[0]),axis=1)\n",
    "test['pickup_distance_queens']=test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],queens[1],queens[0]),axis=1)\n",
    "test['pickup_distance_brooklyn']=test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],brooklyn[1],brooklyn[0]),axis=1)\n",
    "test['pickup_distance_bronx']=test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],bronx[1],bronx[0]),axis=1)\n",
    "test['pickup_distance_statenisland']=test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],staten_island[1],staten_island[0]),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test['dropoff_distance_manhattan']=test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],manhattan[1],manhattan[0]),axis=1)\n",
    "test['dropoff_distance_queens']=test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],queens[1],queens[0]),axis=1)\n",
    "test['dropoff_distance_brooklyn']=test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],brooklyn[1],brooklyn[0]),axis=1)\n",
    "test['dropoff_distance_bronx']=test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],bronx[1],bronx[0]),axis=1)\n",
    "test['dropoff_distance_statenisland']=test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],staten_island[1],staten_island[0]),axis=1)\n",
    "\n",
    "\n",
    "X_train['pickup_distance_manhattan']=X_train.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],manhattan[1],manhattan[0]),axis=1)\n",
    "X_train['pickup_distance_queens']=X_train.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],queens[1],queens[0]),axis=1)\n",
    "X_train['pickup_distance_brooklyn']=X_train.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],brooklyn[1],brooklyn[0]),axis=1)\n",
    "X_train['pickup_distance_bronx']=X_train.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],bronx[1],bronx[0]),axis=1)\n",
    "X_train['pickup_distance_statenisland']=X_train.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],staten_island[1],staten_island[0]),axis=1)\n",
    "\n",
    "X_train['dropoff_distance_manhattan']=X_train.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],manhattan[1],manhattan[0]),axis=1)\n",
    "X_train['dropoff_distance_queens']=X_train.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],queens[1],queens[0]),axis=1)\n",
    "X_train['dropoff_distance_brooklyn']=X_train.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],brooklyn[1],brooklyn[0]),axis=1)\n",
    "X_train['dropoff_distance_bronx']=X_train.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],bronx[1],bronx[0]),axis=1)\n",
    "X_train['dropoff_distance_statenisland']=X_train.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],staten_island[1],staten_island[0]),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test['pickup_distance_manhattan']=X_test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],manhattan[1],manhattan[0]),axis=1)\n",
    "X_test['pickup_distance_queens']=X_test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],queens[1],queens[0]),axis=1)\n",
    "X_test['pickup_distance_brooklyn']=X_test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],brooklyn[1],brooklyn[0]),axis=1)\n",
    "X_test['pickup_distance_bronx']=X_test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],bronx[1],bronx[0]),axis=1)\n",
    "X_test['pickup_distance_statenisland']=X_test.apply(lambda row:distance(row['pickup_latitude'],row['pickup_longitude'],staten_island[1],staten_island[0]),axis=1)\n",
    "\n",
    "X_test['dropoff_distance_manhattan']=X_test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],manhattan[1],manhattan[0]),axis=1)\n",
    "X_test['dropoff_distance_queens']=X_test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],queens[1],queens[0]),axis=1)\n",
    "X_test['dropoff_distance_brooklyn']=X_test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],brooklyn[1],brooklyn[0]),axis=1)\n",
    "X_test['dropoff_distance_bronx']=X_test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],bronx[1],bronx[0]),axis=1)\n",
    "X_test['dropoff_distance_statenisland']=X_test.apply(lambda row:distance(row['dropoff_latitude'],row['dropoff_longitude'],staten_island[1],staten_island[0]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"X_train_cleaned.csv\",index=False)\n",
    "X_test.to_csv(\"X_test_cleaned.csv\",index=False)\n",
    "test.to_csv(\"test_cleaned.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=lgb.Dataset(X_train,label=y_train)\n",
    "param = {'num_leaves':31, 'num_trees':5000, 'objective':'regression'}\n",
    "param['metric'] = 'l2_root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's rmse: 4.97639 + 0.0433001\n",
      "[40]\tcv_agg's rmse: 4.40782 + 0.0470562\n",
      "[60]\tcv_agg's rmse: 4.19551 + 0.0508031\n",
      "[80]\tcv_agg's rmse: 4.08703 + 0.0437323\n",
      "[100]\tcv_agg's rmse: 4.02134 + 0.0462551\n",
      "[120]\tcv_agg's rmse: 3.97853 + 0.0481419\n",
      "[140]\tcv_agg's rmse: 3.94341 + 0.0470577\n",
      "[160]\tcv_agg's rmse: 3.91974 + 0.0477422\n",
      "[180]\tcv_agg's rmse: 3.9016 + 0.0487359\n",
      "[200]\tcv_agg's rmse: 3.88894 + 0.0484676\n",
      "[220]\tcv_agg's rmse: 3.8762 + 0.0489229\n",
      "[240]\tcv_agg's rmse: 3.86516 + 0.0487207\n",
      "[260]\tcv_agg's rmse: 3.85582 + 0.0485204\n",
      "[280]\tcv_agg's rmse: 3.84757 + 0.0480057\n",
      "[300]\tcv_agg's rmse: 3.83991 + 0.0491724\n",
      "[320]\tcv_agg's rmse: 3.83403 + 0.0487574\n",
      "[340]\tcv_agg's rmse: 3.82654 + 0.0480774\n",
      "[360]\tcv_agg's rmse: 3.82131 + 0.0492133\n",
      "[380]\tcv_agg's rmse: 3.81708 + 0.0495516\n",
      "[400]\tcv_agg's rmse: 3.81252 + 0.051389\n",
      "[420]\tcv_agg's rmse: 3.80834 + 0.0525033\n",
      "[440]\tcv_agg's rmse: 3.80426 + 0.0524189\n",
      "[460]\tcv_agg's rmse: 3.80059 + 0.0532246\n",
      "[480]\tcv_agg's rmse: 3.79669 + 0.053099\n",
      "[500]\tcv_agg's rmse: 3.79458 + 0.0540189\n",
      "[520]\tcv_agg's rmse: 3.79115 + 0.0539374\n",
      "[540]\tcv_agg's rmse: 3.78908 + 0.0536211\n",
      "[560]\tcv_agg's rmse: 3.78684 + 0.0534732\n",
      "[580]\tcv_agg's rmse: 3.78443 + 0.0535862\n",
      "[600]\tcv_agg's rmse: 3.7819 + 0.0538512\n",
      "[620]\tcv_agg's rmse: 3.77937 + 0.0535661\n",
      "[640]\tcv_agg's rmse: 3.7773 + 0.0530757\n",
      "[660]\tcv_agg's rmse: 3.77549 + 0.0534545\n",
      "[680]\tcv_agg's rmse: 3.77364 + 0.0538053\n",
      "[700]\tcv_agg's rmse: 3.77216 + 0.0540332\n",
      "[720]\tcv_agg's rmse: 3.7706 + 0.0543162\n",
      "[740]\tcv_agg's rmse: 3.76953 + 0.0546935\n",
      "[760]\tcv_agg's rmse: 3.76818 + 0.0554343\n",
      "[780]\tcv_agg's rmse: 3.76707 + 0.055943\n",
      "[800]\tcv_agg's rmse: 3.76556 + 0.0558314\n",
      "[820]\tcv_agg's rmse: 3.7641 + 0.0552904\n",
      "[840]\tcv_agg's rmse: 3.76266 + 0.0549012\n",
      "[860]\tcv_agg's rmse: 3.76137 + 0.0544923\n",
      "[880]\tcv_agg's rmse: 3.7602 + 0.0537166\n",
      "[900]\tcv_agg's rmse: 3.75955 + 0.0546256\n",
      "[920]\tcv_agg's rmse: 3.75849 + 0.0545605\n",
      "[940]\tcv_agg's rmse: 3.75753 + 0.0552031\n",
      "[960]\tcv_agg's rmse: 3.75627 + 0.0553875\n",
      "[980]\tcv_agg's rmse: 3.75503 + 0.0550817\n",
      "[1000]\tcv_agg's rmse: 3.75447 + 0.0552712\n",
      "[1020]\tcv_agg's rmse: 3.75328 + 0.0547799\n",
      "[1040]\tcv_agg's rmse: 3.75293 + 0.0547221\n",
      "[1060]\tcv_agg's rmse: 3.75222 + 0.0546757\n",
      "[1080]\tcv_agg's rmse: 3.75141 + 0.054923\n",
      "[1100]\tcv_agg's rmse: 3.75059 + 0.0546548\n",
      "[1120]\tcv_agg's rmse: 3.74922 + 0.054782\n",
      "[1140]\tcv_agg's rmse: 3.74806 + 0.0543397\n",
      "[1160]\tcv_agg's rmse: 3.74751 + 0.0538597\n",
      "[1180]\tcv_agg's rmse: 3.74718 + 0.0535384\n",
      "[1200]\tcv_agg's rmse: 3.74638 + 0.0534525\n",
      "[1220]\tcv_agg's rmse: 3.74577 + 0.0536629\n",
      "[1240]\tcv_agg's rmse: 3.74519 + 0.0537526\n",
      "[1260]\tcv_agg's rmse: 3.74471 + 0.0540163\n",
      "[1280]\tcv_agg's rmse: 3.74421 + 0.0544197\n",
      "[1300]\tcv_agg's rmse: 3.74375 + 0.0544095\n",
      "[1320]\tcv_agg's rmse: 3.74318 + 0.0546022\n",
      "[1340]\tcv_agg's rmse: 3.74269 + 0.0546651\n",
      "[1360]\tcv_agg's rmse: 3.7422 + 0.0545152\n",
      "[1380]\tcv_agg's rmse: 3.74188 + 0.0543946\n",
      "[1400]\tcv_agg's rmse: 3.74101 + 0.0545396\n",
      "[1420]\tcv_agg's rmse: 3.74044 + 0.0545609\n",
      "[1440]\tcv_agg's rmse: 3.73987 + 0.0546179\n",
      "[1460]\tcv_agg's rmse: 3.73941 + 0.0547323\n",
      "[1480]\tcv_agg's rmse: 3.7392 + 0.0549465\n",
      "[1500]\tcv_agg's rmse: 3.73868 + 0.054799\n",
      "[1520]\tcv_agg's rmse: 3.73827 + 0.054565\n",
      "[1540]\tcv_agg's rmse: 3.73772 + 0.0541267\n",
      "[1560]\tcv_agg's rmse: 3.73733 + 0.0536952\n",
      "[1580]\tcv_agg's rmse: 3.73688 + 0.0536471\n",
      "[1600]\tcv_agg's rmse: 3.73632 + 0.0538076\n",
      "[1620]\tcv_agg's rmse: 3.73554 + 0.0541403\n",
      "[1640]\tcv_agg's rmse: 3.73543 + 0.0540556\n",
      "[1660]\tcv_agg's rmse: 3.73514 + 0.0539584\n",
      "[1680]\tcv_agg's rmse: 3.73463 + 0.054161\n",
      "[1700]\tcv_agg's rmse: 3.73435 + 0.0542471\n",
      "[1720]\tcv_agg's rmse: 3.73404 + 0.0542656\n",
      "[1740]\tcv_agg's rmse: 3.73396 + 0.0543248\n"
     ]
    }
   ],
   "source": [
    "num_round=1000\n",
    "cv_results = lgb.cv(param, train_data, num_boost_round=num_round, nfold=5,verbose_eval=20, early_stopping_rounds=20,stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num_boost_round: 1737\n"
     ]
    }
   ],
   "source": [
    "print('Best num_boost_round:', len(cv_results['rmse-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "lgb_bst=lgb.train(param,train_data,len(cv_results['rmse-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Light GBM with Feature Engineering is  3.6794217823934643\n"
     ]
    }
   ],
   "source": [
    "lgb_pred = lgb_bst.predict(X_test)\n",
    "lgb_rmse=np.sqrt(mean_squared_error(lgb_pred, y_test))\n",
    "print(\"RMSE for Light GBM with Feature Engineering is \",lgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE for Light GBM with Feature Engineering is 2.8034321159702484\n"
     ]
    }
   ],
   "source": [
    "lgb_train_rmse=np.sqrt(mean_squared_error(lgb_bst.predict(X_train),y_train))\n",
    "print(\"Train RMSE for Light GBM with Feature Engineering is\", lgb_train_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of Light GBM with Feature Engineering is  -0.8759896664232159\n"
     ]
    }
   ],
   "source": [
    "variance=lgb_train_rmse - lgb_rmse\n",
    "print(\"Variance of Light GBM with Feature Engineering is \", variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
